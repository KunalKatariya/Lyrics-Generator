{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word_Level.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KunalKatariya/Lyrics-Generator/blob/master/Word_Level.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "QFLcI3akXXRz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -q keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E8BovXWeX3TX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -q numpy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1MtUhzzEX7O6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -q pandas"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GW_Y2OhRX99K",
        "colab_type": "code",
        "outputId": "17744a3a-9ae0-48e9-a9a4-e7184b2be7a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "''"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "n7LNhi2lYKcJ",
        "colab_type": "code",
        "outputId": "a4ec2816-4207-4e20-f469-df8a0b572ee7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "from keras.callbacks import LambdaCallback, EarlyStopping, ModelCheckpoint\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.layers import LSTM, Bidirectional\n",
        "from keras.layers import Dropout\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "from keras.utils.data_utils import get_file\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import sys\n",
        "import io\n",
        "import re\n",
        "import random"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "AZPtrRn4ZQrj",
        "colab_type": "code",
        "outputId": "9333225b-5401-45af-d1fd-7f9efd1e1f5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/ivan-liljeqvist/ailyrics/master/corpus.txt -P \"/content/drive/My Drive/app\""
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-01-07 18:03:28--  https://raw.githubusercontent.com/ivan-liljeqvist/ailyrics/master/corpus.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7709143 (7.4M) [text/plain]\n",
            "Saving to: ‘/content/drive/My Drive/app/corpus.txt’\n",
            "\n",
            "\rcorpus.txt            0%[                    ]       0  --.-KB/s               \rcorpus.txt          100%[===================>]   7.35M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2019-01-07 18:03:28 (62.3 MB/s) - ‘/content/drive/My Drive/app/corpus.txt’ saved [7709143/7709143]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ruu6TGY3ZYkv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/My Drive/app/corpus.txt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qsl_IeEpZkfR",
        "colab_type": "code",
        "outputId": "9f99e218-e419-486f-f79c-7af8ae148e32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "with io.open(\"/content/drive/My Drive/app/corpus.txt\", encoding = 'utf-8') as f:\n",
        "  text = f.read().lower().replace('\\n', ' \\n ')\n",
        "print(\"Corpus Length in characters: \", len(text))\n",
        "\n",
        "text_in_words = [w for w in text.split(' ') if w.strip() != '' or w == '\\n']\n",
        "print('Corpus length in words:', len(text_in_words))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Corpus Length in characters:  7719341\n",
            "Corpus length in words: 1608123\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UAqb8otyZ-8F",
        "colab_type": "code",
        "outputId": "4e4e07e9-25e8-46a8-bb8d-24dcd5ed213d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "cell_type": "code",
      "source": [
        "#Calculating frequency of words\n",
        "MIN_WORD_FREQUENCY = 10\n",
        "word_freq = {}\n",
        "for word in text_in_words:\n",
        "  word_freq[word] = word_freq.get(word, 0) + 1\n",
        "  \n",
        "ignored_word = set()\n",
        "for k, v in word_freq.items():\n",
        "  if word_freq[k] < MIN_WORD_FREQUENCY:\n",
        "    ignored_word.add(k)\n",
        "\n",
        "words = set(text_in_words)\n",
        "print(\"Unique words before ignoring:\", len(words))\n",
        "print(\"Ignoring words with frequency <\", MIN_WORD_FREQUENCY)\n",
        "words = sorted(set(words) - ignored_word)\n",
        "print(\"Unique words after ignoring:\", len(words))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique words before ignoring: 42129\n",
            "Ignoring words with frequency < 10\n",
            "Unique words after ignoring: 5536\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ylvNlJzgeYsl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "word_indices = dict((c, i) for i, c in enumerate(words))\n",
        "indices_word = dict((i, c) for i, c in enumerate(words))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LC0b5dgNfHNu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "step = 1\n",
        "sequence_len = 10\n",
        "sentences = []\n",
        "next_words = []\n",
        "ignored = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bpyhJF1nhiG8",
        "colab_type": "code",
        "outputId": "18d3e277-dfb1-49b5-fa8d-4c7131f1cb89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "for i in range(0, len(text_in_words) - sequence_len, step):\n",
        "  # Only add the sequences where no word is in ignored_words\n",
        "  if len(set(text_in_words[i: i+sequence_len+1]).intersection(ignored_word)) == 0:\n",
        "    sentences.append(text_in_words[i: i + sequence_len])\n",
        "    next_words.append(text_in_words[i + sequence_len])\n",
        "  else:\n",
        "    ignored = ignored + 1\n",
        "print('Ignored sequences:', ignored)\n",
        "print('Remaining sequences:', len(sentences))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ignored sequences: 586279\n",
            "Remaining sequences: 1021834\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DQUFJZpri4El",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def shuffle_and_split_training_set(sentences_original, next_original, percentage_test=2):\n",
        "  print('Shuffling sentences')\n",
        "\n",
        "  tmp_sentences = []\n",
        "  tmp_next_word = []\n",
        "  for i in np.random.permutation(len(sentences)):\n",
        "    tmp_sentences.append(sentences_original[i])\n",
        "    tmp_next_word.append(next_original[i])\n",
        "\n",
        "  cut_index = int(len(sentences_original) * (1.-(percentage_test/100.)))\n",
        "  x_train, x_test = tmp_sentences[:cut_index], tmp_sentences[cut_index:]\n",
        "  y_train, y_test = tmp_next_word[:cut_index], tmp_next_word[cut_index:]\n",
        "\n",
        "  print(\"Size of training set = %d\" % len(x_train))\n",
        "  print(\"Size of test set = %d\" % len(y_test))\n",
        "  return (x_train, y_train), (x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mrPtkIVGgEFZ",
        "colab_type": "code",
        "outputId": "9cb38875-d14f-4729-91ba-a901d4cc7250",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "cell_type": "code",
      "source": [
        "(sentences, next_words), (sentences_test, next_words_test) = shuffle_and_split_training_set(sentences, next_words)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shuffling sentences\n",
            "Size of training set = 1001397\n",
            "Size of test set = 20437\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IalOaD7Nmn-d",
        "colab_type": "code",
        "outputId": "d0d0cefc-6fcf-4b4b-b46c-95d920e428e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Building model...\")\n",
        "model = Sequential()\n",
        "model.add(Bidirectional(LSTM(128), input_shape=(sequence_len, len(words))))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(len(words)))\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building model...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ax1_L6V1nKZZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cqgM86YGa7IZ",
        "colab_type": "code",
        "outputId": "9f583410-970b-4316-f430-b93b14c148ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bidirectional_1 (Bidirection (None, 256)               5800960   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 5536)              1422752   \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 5536)              0         \n",
            "=================================================================\n",
            "Total params: 7,223,712\n",
            "Trainable params: 7,223,712\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fVnWRGGha_1R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Data generator for fit and evaluate\n",
        "def generator(sentence_list, next_word_list, batch_size):\n",
        "  index = 0\n",
        "  while True:\n",
        "    x = np.zeros((batch_size, sequence_len, len(words)), dtype = np.bool)\n",
        "    y = np.zeros((batch_size, len(words)), dtype = np.bool)\n",
        "    for i in range(batch_size):\n",
        "      for t, w in enumerate(sentence_list[index % len(sentence_list)]):\n",
        "        x[i, t, word_indices[w]] = 1\n",
        "      y[i, word_indices[next_word_list[index % len(sentence_list)]]] = 1\n",
        "      index = index + 1\n",
        "    yield x, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Zs3x_juLdSm0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def sample(preds, temperature = 1.0):\n",
        "  #helper function to sample an index from the probability array\n",
        "  preds = np.asarrays(preds).astype(\"float64\")\n",
        "  preds = np.log(preds)/temperature\n",
        "  exp_preds = np.exp(preds)\n",
        "  preds = exp_preds / np.sum(exp_preds)\n",
        "  probas = np.random.multinomial(1, preds, 1)\n",
        "  return np.argmax(probas)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E0bySLS9ej6A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def on_epoch_end(epoch, logs):\n",
        "  print('----- Generating text after Epoch: %d' % epoch)\n",
        "  \n",
        "  #Randomly pick a seed sentence\n",
        "  seed_index = np.random.randint(len(sentences + sentences_test))\n",
        "  seed = (sentences + sentences_test)[seed_index]\n",
        "  \n",
        "  for diversity in [0.3, 0.4, 0.5, 0.6, 0.7]:\n",
        "    sentence = seed\n",
        "    print('----- diversity:', diversity)\n",
        "    print('----- Generating with seed: \"' + ' '.join(sentence) + '\"')\n",
        "    print(' '.join(sentence))\n",
        "    \n",
        "    for i in range(50):\n",
        "      x_preds = np.zeros((1, sequence_len, len(words)))\n",
        "      for t, word in enumerate(sentence):\n",
        "        x_preds[0, t, word_indices[word]] = 1\n",
        "      preds = model.predict(x_preds, verbose = 0)[0]\n",
        "      next_index = sample(preds, diversity)\n",
        "      next_word = indices_word[next_index]\n",
        "      \n",
        "      sentence = sentence[1:]\n",
        "      sentence.append(next_word)\n",
        "      \n",
        "      sys.stdout.write(\" \" + next_word)\n",
        "    sys.stdout.write(\"\\n\")\n",
        "  sys.stdout.write(\"=\"*80 + \"\\n\")\n",
        "  sys.stdout.flush()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9W8ypZVWjbi8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "\n",
        "print_callback = LambdaCallback(on_epoch_end = on_epoch_end)\n",
        "\n",
        "\n",
        "model.fit_generator(generator(sentences, next_words, batch_size),\n",
        "                   steps_per_epoch = int(len(sentences)/batch_size) + 1,\n",
        "                    epochs = 100,\n",
        "                    callbacks = [print_callback],\n",
        "                    validation_data = generator(sentences_test, next_words_test, batch_size),\n",
        "                    validation_steps = int(len(sentences_test)/batch_size) + 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3weo6NKFZmwG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}